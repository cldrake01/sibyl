{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fJKeVHbhD050",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0b6c8e89-48e6-490c-9e2a-2e52f9a78b40",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:45:57.625764Z",
     "start_time": "2023-12-06T17:45:57.617494Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O564DrUwxVVd",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:00.690380Z",
     "start_time": "2023-12-06T17:45:57.624547Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKsRrd2G0Yba",
    "outputId": "5a321cef-3b64-4090-adc1-a8651d132c5f",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:30.155866Z",
     "start_time": "2023-12-06T17:46:00.697915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\r\n",
      "tar: Error opening archive: Failed to open 'ta-lib-0.4.0-src.tar.gz'\r\n",
      "[Errno 2] No such file or directory: 'ta-lib'\n",
      "/Users/collin/PycharmProjects/dl-quant/notebooks\n",
      "zsh:1: no such file or directory: ./configure\r\n",
      "make: *** No targets specified and no makefile found.  Stop.\r\n",
      "make: *** No rule to make target `install'.  Stop.\r\n",
      "/Users/collin/PycharmProjects/dl-quant\n",
      "\r\n",
      "                  __    __    __    __\r\n",
      "                 /  \\  /  \\  /  \\  /  \\\r\n",
      "                /    \\/    \\/    \\/    \\\r\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\r\n",
      "              /  / \\   / \\   / \\   / \\  \\____\r\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\r\n",
      "            / _/                       \\_____/  `\r\n",
      "            |/\r\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\r\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\r\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\r\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\r\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\r\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\r\n",
      "\r\n",
      "        mamba (1.4.2) supported by @QuantStack\r\n",
      "\r\n",
      "        GitHub:  https://github.com/mamba-org/mamba\r\n",
      "        Twitter: https://twitter.com/QuantStack\r\n",
      "\r\n",
      "█████████████████████████████████████████████████████████████\r\n",
      "\r\n",
      "\r\n",
      "Looking for: ['ta-lib']\r\n",
      "\r\n",
      "\u001B[?25l\u001B[2K\u001B[0G[+] 0.0s\r\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.1s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "pkgs/main/noarch   \u001B[90m━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "pkgs/r/osx-64      \u001B[90m━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "pkgs/r/noarch      \u001B[33m━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\r\n",
      "conda-forge/osx-64 \u001B[90m━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.2s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "pkgs/main/noarch   \u001B[90m━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "pkgs/r/osx-64      \u001B[90m━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "pkgs/r/noarch      \u001B[33m━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.3s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━\u001B[0m 417.8kB /  ??.?MB @   1.5MB/s  0.3s\r\n",
      "pkgs/main/noarch   \u001B[90m━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━\u001B[0m 462.9kB /  ??.?MB @   1.7MB/s  0.3s\r\n",
      "pkgs/r/osx-64      \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m 340.0kB /  ??.?MB @   1.2MB/s  0.3s\r\n",
      "pkgs/r/noarch      \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━\u001B[0m 385.0kB /  ??.?MB @   1.4MB/s  0.3s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━\u001B[0m 254.6kB /  ??.?MB @ 952.5kB/s  0.3s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0Gpkgs/main/noarch                                   853.7kB @   2.5MB/s  0.4s\r\n",
      "[+] 0.4s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m 864.3kB /  ??.?MB @   2.3MB/s  0.4s\r\n",
      "pkgs/r/osx-64      \u001B[90m━━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━\u001B[0m 770.1kB /  ??.?MB @   2.0MB/s  0.4s\r\n",
      "pkgs/r/noarch      \u001B[90m━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m 921.6kB /  ??.?MB @   2.4MB/s  0.4s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m 815.3kB /  ??.?MB @   2.5MB/s  0.4s\r\n",
      "conda-forge/noarch \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.1s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0Gpkgs/r/osx-64                                      820.9kB @   2.0MB/s  0.4s\r\n",
      "[+] 0.5s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━\u001B[0m   1.1MB /  ??.?MB @   2.4MB/s  0.5s\r\n",
      "pkgs/r/noarch      \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m   1.3MB /  ??.?MB @   2.8MB/s  0.5s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━\u001B[0m   1.8MB /  ??.?MB @   3.7MB/s  0.5s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.2s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.6s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━\u001B[0m   1.3MB /  ??.?MB @   2.5MB/s  0.6s\r\n",
      "pkgs/r/noarch      \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   1.9MB /  ??.?MB @   3.2MB/s  0.6s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m   2.4MB /  ??.?MB @   4.4MB/s  0.6s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━\u001B[0m   0.0 B /  ??.?MB @  ??.?MB/s  0.3s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.7s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m   1.9MB /  ??.?MB @   2.9MB/s  0.7s\r\n",
      "pkgs/r/noarch      \u001B[90m━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━\u001B[0m   2.3MB /  ??.?MB @   3.2MB/s  0.7s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━\u001B[0m   3.3MB /  ??.?MB @   5.1MB/s  0.7s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m 253.4kB /  ??.?MB @ 386.8kB/s  0.4s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 0.8s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━\u001B[0m   2.2MB @   3.0MB/s             0.8s\r\n",
      "pkgs/r/noarch      ━━━━━━━━━━━━━━━━━━━━━━━━   2.3MB @   3.2MB/s Finalizing  0.8s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━\u001B[0m   3.6MB @   5.1MB/s             0.8s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━\u001B[0m 886.3kB @   1.2MB/s             0.5s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0Gpkgs/r/noarch                                      @   3.2MB/s  0.8s\r\n",
      "[+] 0.9s\r\n",
      "pkgs/main/osx-64   \u001B[90m╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m   2.8MB /  ??.?MB @   3.3MB/s  0.9s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━\u001B[0m   4.3MB /  ??.?MB @   5.0MB/s  0.9s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m   1.8MB /  ??.?MB @   2.0MB/s  0.6s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.0s\r\n",
      "pkgs/main/osx-64   \u001B[90m━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m   3.0MB /  ??.?MB @   3.3MB/s  1.0s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m   5.4MB /  ??.?MB @   5.7MB/s  1.0s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m   3.0MB /  ??.?MB @   3.1MB/s  0.7s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.1s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m   3.6MB /  ??.?MB @   3.4MB/s  1.1s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m   6.4MB /  ??.?MB @   6.0MB/s  1.1s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m   3.9MB /  ??.?MB @   3.7MB/s  0.8s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.2s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━\u001B[0m   4.0MB /  ??.?MB @   3.5MB/s  1.2s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m   7.1MB /  ??.?MB @   6.1MB/s  1.2s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m   4.6MB /  ??.?MB @   3.9MB/s  0.9s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.3s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m   4.6MB /  ??.?MB @   3.6MB/s  1.3s\r\n",
      "conda-forge/osx-64 \u001B[90m━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m   7.8MB /  ??.?MB @   6.1MB/s  1.3s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m   5.5MB /  ??.?MB @   4.3MB/s  1.0s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.4s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m   4.9MB /  ??.?MB @   3.6MB/s  1.4s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m   8.5MB /  ??.?MB @   6.2MB/s  1.4s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m   6.4MB /  ??.?MB @   4.6MB/s  1.1s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.5s\r\n",
      "pkgs/main/osx-64   \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m   5.4MB /  ??.?MB @   3.7MB/s  1.5s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   9.4MB /  ??.?MB @   6.3MB/s  1.5s\r\n",
      "conda-forge/noarch \u001B[90m━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m   7.2MB /  ??.?MB @   4.9MB/s  1.2s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.6s\r\n",
      "pkgs/main/osx-64   \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m   5.9MB /  ??.?MB @   3.7MB/s  1.6s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m  10.3MB /  ??.?MB @   6.5MB/s  1.6s\r\n",
      "conda-forge/noarch \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m   8.0MB /  ??.?MB @   5.0MB/s  1.3s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.7s\r\n",
      "pkgs/main/osx-64   ━━━━━━━━━━━━━━━━━━━━━━━━   6.1MB @   3.7MB/s Finalizing  1.7s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m  10.8MB @   6.6MB/s             1.7s\r\n",
      "conda-forge/noarch \u001B[90m━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   8.4MB @   5.1MB/s             1.4s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.8s\r\n",
      "pkgs/main/osx-64   ━━━━━━━━━━━━━━━━━━━━━━━━   6.1MB @   3.7MB/s Finalizing  1.8s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m  10.8MB @   6.6MB/s             1.8s\r\n",
      "conda-forge/noarch \u001B[90m━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   8.4MB @   5.1MB/s             1.5s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 1.9s\r\n",
      "pkgs/main/osx-64   ━━━━━━━━━━━━━━━━━━━━━━━━   6.1MB @   3.7MB/s Finalizing  1.9s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━\u001B[0m  10.8MB @   6.6MB/s             1.9s\r\n",
      "conda-forge/noarch \u001B[90m━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   8.4MB @   5.1MB/s             1.6s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0Gpkgs/main/osx-64                                   @   3.7MB/s  1.9s\r\n",
      "[+] 2.0s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━\u001B[0m  12.7MB /  ??.?MB @   6.4MB/s  2.0s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m   9.2MB /  ??.?MB @   4.7MB/s  1.7s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.1s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m  13.9MB /  ??.?MB @   6.8MB/s  2.1s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m  11.3MB /  ??.?MB @   5.5MB/s  1.8s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.2s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m  14.7MB /  ??.?MB @   6.8MB/s  2.2s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━\u001B[0m  12.1MB /  ??.?MB @   5.6MB/s  1.9s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.3s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m  15.5MB /  ??.?MB @   6.9MB/s  2.3s\r\n",
      "conda-forge/noarch \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m  12.5MB /  ??.?MB @   5.5MB/s  2.0s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.4s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━\u001B[0m  16.3MB /  ??.?MB @   6.9MB/s  2.4s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m  13.3MB /  ??.?MB @   5.6MB/s  2.1s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.5s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m  17.2MB /  ??.?MB @   7.0MB/s  2.5s\r\n",
      "conda-forge/noarch \u001B[33m━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m  14.1MB /  ??.?MB @   5.7MB/s  2.2s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.6s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m  17.6MB @   7.0MB/s             2.6s\r\n",
      "conda-forge/noarch ━━━━━━━━━━━━━━━━━━━━━━━━  14.9MB @   5.8MB/s Finalizing  2.3s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.7s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m  17.6MB @   7.0MB/s             2.7s\r\n",
      "conda-forge/noarch ━━━━━━━━━━━━━━━━━━━━━━━━  14.9MB @   5.8MB/s Finalizing  2.4s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.8s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m  17.6MB @   7.0MB/s             2.8s\r\n",
      "conda-forge/noarch ━━━━━━━━━━━━━━━━━━━━━━━━  14.9MB @   5.8MB/s Finalizing  2.5s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 2.9s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━\u001B[0m  17.6MB @   7.0MB/s             2.9s\r\n",
      "conda-forge/noarch ━━━━━━━━━━━━━━━━━━━━━━━━  14.9MB @   5.8MB/s Finalizing  2.6s\u001B[2K\u001B[1A\u001B[2K\u001B[1A\u001B[2K\u001B[0Gconda-forge/noarch                                 @   5.8MB/s  2.6s\r\n",
      "[+] 3.0s\r\n",
      "conda-forge/osx-64 \u001B[90m━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━\u001B[0m  18.7MB /  ??.?MB @   6.3MB/s  3.0s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.1s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━\u001B[0m  20.7MB /  ??.?MB @   6.8MB/s  3.1s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.2s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m  21.4MB /  ??.?MB @   6.8MB/s  3.2s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.3s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m  22.2MB /  ??.?MB @   6.8MB/s  3.3s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.4s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━\u001B[0m  22.9MB /  ??.?MB @   6.8MB/s  3.4s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.5s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m  23.6MB /  ??.?MB @   6.8MB/s  3.5s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.6s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m  24.4MB /  ??.?MB @   6.8MB/s  3.6s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.7s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━\u001B[0m  24.8MB /  ??.?MB @   6.8MB/s  3.7s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.8s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━\u001B[0m  26.0MB /  ??.?MB @   6.9MB/s  3.8s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 3.9s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m  26.7MB /  ??.?MB @   6.9MB/s  3.9s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.0s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━\u001B[0m  27.2MB /  ??.?MB @   6.8MB/s  4.0s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.1s\r\n",
      "conda-forge/osx-64 \u001B[90m━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━━━\u001B[0m  27.9MB /  ??.?MB @   6.8MB/s  4.1s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.2s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━━\u001B[0m  28.5MB /  ??.?MB @   6.8MB/s  4.2s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.3s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━╸\u001B[0m\u001B[90m━━━\u001B[0m  28.8MB /  ??.?MB @   6.8MB/s  4.3s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.4s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━━━\u001B[0m  29.6MB /  ??.?MB @   6.8MB/s  4.4s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.5s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━━━━\u001B[0m  30.3MB /  ??.?MB @   6.8MB/s  4.5s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.6s\r\n",
      "conda-forge/osx-64 \u001B[90m━━━━━━━━━━━━━╸\u001B[0m\u001B[33m━━━━━━━━━━━\u001B[0m  31.1MB /  ??.?MB @   6.8MB/s  4.6s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.7s\r\n",
      "conda-forge/osx-64 \u001B[33m━━━━━━━╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m  31.9MB /  ??.?MB @   6.8MB/s  4.7s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.8s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  4.8s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 4.9s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  4.9s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.0s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.0s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.1s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.1s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.2s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.2s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.3s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.3s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.4s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.4s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.5s\r\n",
      "conda-forge/osx-64 ━━━━━━━━━━━━━━━━━━━━━━━━  32.6MB @   6.9MB/s Finalizing  5.5s\u001B[2K\u001B[1A\u001B[2K\u001B[0G[+] 5.6s\r\n",
      "\u001B[2K\u001B[1A\u001B[2K\u001B[0Gconda-forge/osx-64                                 @   6.9MB/s  5.6s\r\n",
      "\u001B[?25h\r\n",
      "Pinned packages:\r\n",
      "  - python 3.11.*\r\n",
      "\r\n",
      "\r\n",
      "Could not solve for environment specs\r\n",
      "The following packages are incompatible\r\n",
      "└─ \u001B[32mta-lib  \u001B[0m is installable with the potential options\r\n",
      "   ├─ \u001B[32mta-lib [0.4.18|0.4.19]\u001B[0m would require\r\n",
      "   │  └─ \u001B[32mpython >=3.6,<3.7.0a0 \u001B[0m, which can be installed;\r\n",
      "   ├─ \u001B[32mta-lib [0.4.18|0.4.19]\u001B[0m would require\r\n",
      "   │  └─ \u001B[32mpython >=3.7,<3.8.0a0 \u001B[0m, which can be installed;\r\n",
      "   ├─ \u001B[32mta-lib [0.4.18|0.4.19|0.4.28]\u001B[0m would require\r\n",
      "   │  └─ \u001B[32mpython >=3.8,<3.9.0a0 \u001B[0m, which can be installed;\r\n",
      "   ├─ \u001B[32mta-lib [0.4.19|0.4.28]\u001B[0m would require\r\n",
      "   │  └─ \u001B[32mpython >=3.10,<3.11.0a0 \u001B[0m, which can be installed;\r\n",
      "   └─ \u001B[32mta-lib [0.4.19|0.4.28]\u001B[0m would require\r\n",
      "      └─ \u001B[32mpython >=3.9,<3.10.0a0 \u001B[0m, which can be installed.\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "%cd ta-lib\n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "%cd ..\n",
    "!mamba install TA-Lib\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUB23hjM2PlA",
    "outputId": "ef398fcf-9bc9-489e-bf35-18264ed28d6a",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.743791Z",
     "start_time": "2023-12-06T17:46:30.152690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alpaca-py in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (0.13.3)\r\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.3 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (1.0.7)\r\n",
      "Requirement already satisfied: pandas>=1.5.3 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (2.1.1)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.3 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (2.5.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.30.0 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (2.31.0)\r\n",
      "Requirement already satisfied: sseclient-py<2.0.0,>=1.7.2 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (1.8.0)\r\n",
      "Requirement already satisfied: websockets<12.0.0,>=11.0.3 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from alpaca-py) (11.0.3)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pandas>=1.5.3->alpaca-py) (1.26.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pandas>=1.5.3->alpaca-py) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pandas>=1.5.3->alpaca-py) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pandas>=1.5.3->alpaca-py) (2023.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (2.14.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.3->alpaca-py) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from requests<3.0.0,>=2.30.0->alpaca-py) (2023.11.17)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/collin/anaconda3/envs/dl-quant/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.3->alpaca-py) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install alpaca-py\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data import StockBarsRequest, TimeFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "i3oKlUlzyYrZ",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.755681Z",
     "start_time": "2023-12-06T17:46:32.744245Z"
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = \"PK3D0P0EF5NVU7LKHY76\"\n",
    "API_SECRET = \"X2kmdCqfYzGxaCYG2C3UhQ9DqHT9bYhYUhXM2g6G\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Z3fKSxo1yCSg",
    "outputId": "38d19831-d47f-44dd-a140-5654d8aca838",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.795056Z",
     "start_time": "2023-12-06T17:46:32.771234Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "754"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_tickers = [\n",
    "    \"AAPL\", \"MSFT\", \"GOOGL\", \"GOOG\", \"AMZN\", \"TSLA\", \"FB\", \"BRK.B\", \"JPM\", \"JNJ\",\n",
    "    \"NVDA\", \"V\", \"PG\", \"MA\", \"UNH\", \"PYPL\", \"HD\", \"DIS\", \"BAC\", \"CMCSA\",\n",
    "    \"TMO\", \"ADBE\", \"XOM\", \"CRM\", \"INTC\", \"PEP\", \"VZ\", \"MRK\", \"NFLX\", \"PFE\",\n",
    "    \"KO\", \"ABBV\", \"T\", \"CSCO\", \"ABBV\", \"CVX\", \"NKE\", \"WMT\", \"COST\", \"MCD\",\n",
    "    \"C\", \"ABT\", \"MRNA\", \"QCOM\", \"GILD\", \"TGT\", \"LOW\", \"BMY\", \"HON\", \"DHR\",\n",
    "    \"SBUX\", \"AVGO\", \"PM\", \"ORCL\", \"IBM\", \"MS\", \"UPS\", \"CHTR\", \"CAT\", \"LMT\",\n",
    "    \"NEE\", \"GS\", \"MMM\", \"AMGN\", \"MO\", \"AMAT\", \"TXN\", \"BKNG\", \"LLY\", \"ADP\",\n",
    "    \"NOW\", \"ISRG\", \"ANTM\", \"TFC\", \"CVS\", \"VRTX\", \"USB\", \"DUK\", \"TMUS\", \"CCI\",\n",
    "    \"PLD\", \"SPGI\", \"ECL\", \"GPN\", \"BLK\", \"GM\", \"BDX\", \"ICE\", \"SO\", \"CI\", \"ETN\",\n",
    "    \"FDX\", \"GD\", \"LRCX\", \"EOG\", \"APD\", \"SHW\", \"PNC\", \"MET\", \"NSC\", \"AON\",\n",
    "    \"ADSK\", \"CL\", \"MMC\", \"CB\", \"TROW\", \"MCO\", \"EQIX\", \"TMX\", \"TDG\", \"COF\",\n",
    "    \"BAX\", \"SYK\", \"PSX\", \"BIIB\", \"FIS\", \"ITW\", \"WM\", \"DG\", \"AEP\", \"FD\", \"EMR\",\n",
    "    \"LHX\", \"SNP\", \"AZO\", \"ROST\", \"NOC\", \"AIG\", \"KR\", \"ESS\", \"VRTX\", \"SCHW\",\n",
    "    \"CTSH\", \"CTAS\", \"STZ\", \"FE\", \"AFL\", \"WBA\", \"AMP\", \"TROW\", \"SO\", \"BLL\",\n",
    "    \"WELL\", \"MKC\", \"EOG\", \"KMB\", \"DUK\", \"AEP\", \"DTE\", \"CBRE\", \"EXC\", \"BKR\",\n",
    "    \"PPL\", \"WEC\", \"AWK\", \"ALLE\", \"EIX\", \"VRSN\", \"D\", \"WLTW\", \"UDR\", \"LDOS\",\n",
    "    \"HLT\", \"FLT\", \"VTRS\", \"PXD\", \"EW\", \"ATO\", \"CDW\", \"PAYC\", \"FTNT\", \"OTIS\",\n",
    "    \"TDY\", \"CDNS\", \"MSCI\", \"ZBRA\", \"TWTR\", \"FTV\", \"KEYS\", \"STE\", \"ANSS\", \"SNPS\",\n",
    "    \"ZTS\", \"LBRDK\", \"IQV\", \"MKTX\", \"RMD\", \"MXIM\", \"CRL\", \"FRC\", \"CPRT\", \"IDXX\",\n",
    "    \"JKHY\", \"AJG\", \"PEAK\", \"ESS\", \"CTXS\", \"URI\", \"SWK\", \"DLR\", \"VNO\", \"FAST\",\n",
    "    \"LNT\", \"BR\", \"AIZ\", \"ALGN\", \"UAA\", \"MLM\", \"TTWO\", \"CPB\", \"CINF\", \"VFC\",\n",
    "    \"KSU\", \"FTNT\", \"TDY\", \"LW\", \"WAB\", \"HRL\", \"AME\", \"ATO\", \"HIG\", \"HBAN\",\n",
    "    \"ROL\", \"ANET\", \"WRB\", \"NUE\", \"UDR\", \"ARE\", \"RSG\", \"FTV\", \"NVR\", \"J\",\n",
    "    \"MKTX\", \"FLT\", \"ABMD\", \"AKAM\", \"AVB\", \"RHI\", \"SNPS\", \"ZBRA\", \"IDXX\", \"CARR\",\n",
    "    \"RE\", \"LYV\", \"CBRE\", \"CMI\", \"DVA\", \"LVS\", \"CTLT\", \"DXCM\", \"CERN\", \"AAL\",\n",
    "    \"COG\", \"SIVB\", \"KMX\", \"HST\", \"NTRS\", \"CHRW\", \"ZION\", \"TPR\", \"APA\", \"CBOE\",\n",
    "    \"VTR\", \"DVN\", \"LH\", \"NI\", \"WY\", \"CMS\", \"GL\", \"EXPE\", \"LYB\", \"O\", \"VLO\",\n",
    "    \"NCLH\", \"FFIV\", \"L\", \"TDG\", \"BBWI\", \"HCA\", \"UNM\", \"JNPR\", \"MAS\", \"WDC\",\n",
    "    \"BKR\", \"NOV\", \"CNP\", \"MGM\", \"XRX\", \"PVH\", \"UHS\", \"VNT\", \"APA\", \"AES\",\n",
    "    \"DXC\", \"GPS\", \"BRX\", \"PRGO\", \"NRG\", \"RJF\", \"FLS\", \"F\", \"TDG\", \"HOLX\", \"PWR\",\n",
    "    \"URI\", \"AAP\", \"NLOK\", \"HP\", \"NWL\", \"MHK\", \"VAR\", \"LEG\", \"WELL\", \"COTY\",\n",
    "    \"FLR\", \"ARNC\", \"FANG\", \"KEY\", \"LKQ\", \"SEE\", \"FLIR\", \"HFC\", \"NRG\", \"BHF\",\n",
    "    \"DISCK\", \"DISCA\", \"FMC\", \"BEN\", \"PKG\", \"AJG\", \"MHK\", \"IVZ\", \"CF\", \"NWSA\",\n",
    "    \"NWS\", \"PBCT\", \"XRX\", \"EXR\", \"WRK\", \"TAP\", \"HFC\", \"DISH\", \"PKG\", \"OXY\",\n",
    "    \"IVZ\", \"UA\", \"DISCK\", \"DISCA\", \"NWL\", \"FOX\", \"MHK\", \"HPE\", \"NOV\", \"TAP\",\n",
    "    \"KSS\", \"BEN\", \"EXR\", \"PBCT\", \"NWSA\", \"NWS\", \"UA\", \"DISH\", \"FOX\", \"OXY\",\n",
    "    \"ADS\", \"KHC\", \"MOS\", \"PVH\", \"DXC\", \"UA\", \"NBL\", \"ADS\", \"KHC\", \"PVH\", \"DXC\",\n",
    "    \"MOS\", \"SYF\", \"ZBH\", \"NCLH\", \"BRX\", \"MRO\", \"GPS\", \"L\", \"UAA\", \"FLS\", \"FLR\",\n",
    "    \"RJF\", \"RJF\", \"JNPR\", \"UHS\", \"HCA\", \"BBWI\", \"HP\", \"NLOK\", \"AAP\", \"HOLX\",\n",
    "    \"PWR\", \"ARNC\", \"COTY\", \"LEG\", \"VAR\", \"MHK\", \"FANG\", \"FLIR\", \"SEE\", \"LKQ\",\n",
    "    \"KEY\", \"BHF\", \"FMC\", \"DISCK\", \"DISCA\", \"BEN\", \"PKG\", \"IVZ\", \"CF\", \"NWSA\",\n",
    "    \"NWS\", \"PBCT\", \"XRX\", \"EXR\", \"WRK\", \"TAP\", \"HFC\", \"DISH\", \"PKG\", \"OXY\",\n",
    "    \"IVZ\", \"UA\", \"FOX\", \"NWL\", \"MHK\", \"HPE\", \"NOV\", \"TAP\", \"KSS\", \"BEN\", \"EXR\",\n",
    "    \"PBCT\", \"NWSA\", \"NWS\", \"UA\", \"DISH\", \"FOX\", \"OXY\", \"ADS\", \"KHC\", \"MOS\",\n",
    "    \"PVH\", \"DXC\", \"UA\", \"NBL\", \"ADS\", \"KHC\", \"PVH\", \"DXC\", \"MOS\", \"SYF\", \"ZBH\",\n",
    "    \"NCLH\", \"BRX\", \"MRO\", \"GPS\", \"L\", \"UAA\", \"FLS\", \"FLR\", \"RJF\", \"JNPR\", \"UHS\",\n",
    "    \"HCA\", \"BBWI\", \"HP\", \"NLOK\", \"AAP\", \"HOLX\", \"PWR\", \"ARNC\", \"COTY\", \"LEG\",\n",
    "    \"VAR\", \"MHK\", \"FANG\", \"FLIR\", \"SEE\", \"LKQ\", \"KEY\", \"BHF\", \"FMC\", \"DISCK\",\n",
    "    \"DISCA\", \"BEN\", \"PKG\", \"IVZ\", \"CF\", \"NWSA\", \"NWS\", \"PBCT\", \"XRX\", \"EXR\",\n",
    "    \"WRK\", \"TAP\", \"HFC\", \"DISH\", \"PKG\", \"OXY\", \"IVZ\", \"UA\", \"FOX\", \"NWL\", \"MHK\",\n",
    "    \"HPE\", \"NOV\", \"TAP\", \"KSS\", \"BEN\", \"EXR\", \"PBCT\", \"NWSA\", \"NWS\", \"UA\",\n",
    "    \"DISH\", \"FOX\", \"OXY\", \"ADS\", \"KHC\", \"MOS\", \"PVH\", \"DXC\", \"UA\", \"NBL\", \"ADS\",\n",
    "    \"KHC\", \"PVH\", \"DXC\", \"MOS\", \"SYF\", \"ZBH\", \"NCLH\", \"BRX\", \"MRO\", \"GPS\", \"L\",\n",
    "    \"UAA\", \"FLS\", \"FLR\", \"RJF\", \"JNPR\", \"UHS\", \"HCA\", \"BBWI\", \"HP\", \"NLOK\",\n",
    "    \"AAP\", \"HOLX\", \"PWR\", \"ARNC\", \"COTY\", \"LEG\", \"VAR\", \"MHK\", \"FANG\", \"FLIR\",\n",
    "    \"SEE\", \"LKQ\", \"KEY\", \"BHF\", \"FMC\", \"DISCK\", \"DISCA\", \"BEN\", \"PKG\", \"IVZ\",\n",
    "    \"CF\", \"NWSA\", \"NWS\", \"PBCT\", \"XRX\", \"EXR\", \"WRK\", \"TAP\", \"HFC\", \"DISH\",\n",
    "    \"PKG\", \"OXY\", \"IVZ\", \"UA\", \"FOX\", \"NWL\", \"MHK\", \"HPE\", \"NOV\", \"TAP\", \"KSS\",\n",
    "    \"BEN\", \"EXR\", \"PBCT\", \"NWSA\", \"NWS\", \"UA\", \"DISH\", \"FOX\", \"OXY\", \"ADS\",\n",
    "    \"KHC\", \"MOS\", \"PVH\", \"DXC\", \"UA\", \"NBL\", \"ADS\", \"KHC\", \"PVH\", \"DXC\", \"MOS\",\n",
    "    \"SYF\", \"ZBH\", \"NCLH\", \"BRX\", \"MRO\", \"GPS\", \"L\", \"UAA\", \"FLS\", \"FLR\", \"RJF\",\n",
    "    \"JNPR\", \"UHS\", \"HCA\", \"BBWI\", \"HP\", \"NLOK\", \"AAP\", \"HOLX\", \"PWR\", \"ARNC\",\n",
    "    \"COTY\", \"LEG\", \"VAR\", \"MHK\", \"FANG\", \"FLIR\", \"SEE\", \"LKQ\", \"KEY\", \"BHF\",\n",
    "    \"FMC\", \"DISCK\", \"DISCA\", \"BEN\", \"PKG\", \"IVZ\", \"CF\", \"NWSA\", \"NWS\", \"PBCT\",\n",
    "    \"XRX\", \"EXR\", \"WRK\", \"TAP\", \"HFC\", \"DISH\", \"PKG\", \"OXY\", \"IVZ\", \"UA\", \"FOX\",\n",
    "    \"NWL\", \"MHK\", \"HPE\", \"NOV\", \"TAP\", \"KSS\", \"BEN\", \"EXR\", \"PBCT\", \"NWSA\",\n",
    "    \"NWS\", \"UA\", \"DISH\", \"FOX\", \"OXY\", \"ADS\", \"KHC\", \"MOS\", \"PVH\", \"DXC\", \"UA\",\n",
    "    \"NBL\", \"ADS\", \"KHC\", \"PVH\", \"DXC\", \"MOS\", \"SYF\", \"ZBH\", \"NCLH\", \"BRX\",\n",
    "    \"MRO\", \"GPS\", \"L\", \"UAA\", \"FLS\", \"FLR\", \"RJF\", \"JNPR\", \"UHS\", \"HCA\", \"BBWI\",\n",
    "    \"HP\", \"NLOK\", \"AAP\", \"HOLX\", \"PWR\", \"ARNC\", \"COTY\", \"LEG\", \"VAR\", \"MHK\",\n",
    "    \"FANG\", \"FLIR\", \"SEE\", \"LKQ\", \"KEY\", \"BHF\", \"FMC\", \"DISCK\", \"DISCA\", \"BEN\",\n",
    "    \"PKG\", \"IVZ\", \"CF\", \"NWSA\", \"NWS\", \"PBCT\", \"XRX\", \"EXR\", \"WRK\", \"TAP\", \"HFC\",\n",
    "    \"DISH\", \"PKG\", \"OXY\", \"IVZ\", \"UA\", \"FOX\", \"NWL\", \"MHK\", \"HPE\", \"NOV\", \"TAP\",\n",
    "    \"KSS\", \"BEN\", \"EXR\", \"PBCT\"\n",
    "]\n",
    "len(sp_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ocJ7nLN6H0hz",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.829440Z",
     "start_time": "2023-12-06T17:46:32.779565Z"
    }
   },
   "outputs": [],
   "source": [
    "class Vec(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Vec, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 32, batch_first=True)  # Reduced complexity\n",
    "        self.dropout1 = nn.Dropout(0.5)  # Added dropout\n",
    "        self.lstm2 = nn.LSTM(32, 32, batch_first=True)  # Reduced complexity\n",
    "        self.dropout2 = nn.Dropout(0.5)  # Added dropout\n",
    "        self.linear = nn.Linear(32, 15)\n",
    "\n",
    "    def forward(self, input, future=0):\n",
    "        outputs = []\n",
    "        h_t, _ = self.lstm1(input)\n",
    "        h_t = self.dropout1(h_t)\n",
    "        h_t2, _ = self.lstm2(h_t)\n",
    "        h_t2 = self.dropout2(h_t2)\n",
    "        output = self.linear(h_t2[:, -1, :])\n",
    "        outputs += [output]\n",
    "        for i in range(future):  # if we should predict the future\n",
    "            h_t, _ = self.lstm1(output.unsqueeze(1))\n",
    "            h_t2, _ = self.lstm2(h_t)\n",
    "            output = self.linear(h_t2[:, -1, :])\n",
    "            outputs += [output]\n",
    "        outputs = torch.cat(outputs, dim=1)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class MetaLabeler(nn.Module):\n",
    "    \"\"\"\n",
    "    A transformer model for determining the magnitude of Vec's and RVec's proposed trades. MetaLabeler is trained\n",
    "    upon Vec's and RVec's predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(MetaLabeler, self).__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, data, input_window_size=60, output_window_size=15):\n",
    "        self.data = data\n",
    "        self.input_window_size = input_window_size\n",
    "        self.output_window_size = output_window_size\n",
    "        self.total_window_size = input_window_size + output_window_size\n",
    "\n",
    "    def __len__(self):\n",
    "        print(self.data.shape[1], self.total_window_size)\n",
    "        print(self.data.shape[1] - self.total_window_size + 1)\n",
    "        return self.data.shape[1] - self.total_window_size + 1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Loop through each stock and yield a window for the given index\n",
    "        input_batch = []\n",
    "        output_batch = []\n",
    "        for stock_index in range(self.data.shape[0]):\n",
    "            input_window = self.data[stock_index, :, index: index + self.input_window_size]\n",
    "            output_window = self.data[stock_index, :, index + self.input_window_size: index + self.total_window_size]\n",
    "            input_batch.append(input_window)\n",
    "            output_batch.append(output_window)\n",
    "\n",
    "        return torch.stack(input_batch), torch.stack(output_batch)\n"
   ],
   "metadata": {
    "id": "lIQlUviT3cwN",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.843467Z",
     "start_time": "2023-12-06T17:46:32.817155Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NullLogger:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def info(self, *args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def debug(self, *args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def warning(self, *args, **kwargs):\n",
    "        ...\n",
    "\n",
    "    def error(self, *args, **kwargs):\n",
    "        ..."
   ],
   "metadata": {
    "id": "ZogI7VxPSGJE",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.844072Z",
     "start_time": "2023-12-06T17:46:32.821937Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bfl0uIa_ydEK",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.845412Z",
     "start_time": "2023-12-06T17:46:32.828083Z"
    }
   },
   "outputs": [],
   "source": [
    "def alpaca_time_series(\n",
    "    stocks: list[str], start: datetime or str, end: datetime or str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve data from the Alpaca API.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(start, datetime):\n",
    "        start = start.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    if isinstance(end, datetime):\n",
    "        end = end.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    client = StockHistoricalDataClient(\n",
    "        API_KEY,\n",
    "        API_SECRET,\n",
    "    )\n",
    "\n",
    "    # url_override=\"https://data.alpaca.markets\",\n",
    "\n",
    "    params = StockBarsRequest(\n",
    "        symbol_or_symbols=stocks,\n",
    "        start=start,\n",
    "        end=end,\n",
    "        timeframe=TimeFrame.Minute,\n",
    "    )\n",
    "\n",
    "    return client.get_stock_bars(params).data\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def fetch_data(\n",
    "    years: float,\n",
    "    max_workers: int = len(sp_tickers) // 2,\n",
    "    log: logging.Logger = NullLogger(),\n",
    ") -> list:\n",
    "    # Retrieve data from the Alpaca API\n",
    "    log.info(\"Retrieving data from the Alpaca API...\")\n",
    "    log.info(f\"Maximum Worker-threads: {max_workers}\")\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(\n",
    "                alpaca_time_series,\n",
    "                [ticker],\n",
    "                datetime.today() - timedelta(365 * years),\n",
    "                datetime.today(),\n",
    "            )\n",
    "            for ticker in sp_tickers\n",
    "        ]\n",
    "\n",
    "    # Collecting results\n",
    "    data: list = [future.result() for future in futures]\n",
    "    log.info(\"Retrieved data from the Alpaca API.\")\n",
    "\n",
    "    return data\n"
   ],
   "metadata": {
    "id": "ecWlJP-nkPlX",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.846349Z",
     "start_time": "2023-12-06T17:46:32.834269Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7cCAsKOTxGYW",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.861699Z",
     "start_time": "2023-12-06T17:46:32.846591Z"
    }
   },
   "outputs": [],
   "source": [
    "def stock_tensors(stock_data) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Applies the `generate_indicators` function to each stock in the input dictionary, pads each resulting tensor to the\n",
    "    maximum dimension among them, and then stacks them into a single tensor.\n",
    "\n",
    "    :param stock_data: A dictionary where the keys are stock names and the values are time series data for each stock.\n",
    "\n",
    "    :returns torch.Tensor: A tensor that is the result of stacking the padded tensors obtained from each stock's time\n",
    "    series data.\n",
    "    \"\"\"\n",
    "    indicator_tensors_list = []\n",
    "\n",
    "    if type(stock_data) is dict:\n",
    "        indicator_tensors_list = [\n",
    "            indicators(stock) for stock in list(stock_data.values())\n",
    "        ]\n",
    "    else:\n",
    "        # Aggregate all dictionaries contained within the list.\n",
    "        aggregated_data = {}\n",
    "        for stock_dict in stock_data:\n",
    "            for symbol, data in stock_dict.items():\n",
    "                aggregated_data[symbol] = data\n",
    "\n",
    "        indicator_tensors_list = [\n",
    "            indicators(stock) for stock in list(aggregated_data.values())\n",
    "        ]\n",
    "\n",
    "    max_dim = max([stock.shape[1] for stock in indicator_tensors_list])\n",
    "    padded_indicator_tensors = [\n",
    "        torch.nn.functional.pad(\n",
    "            stock, (max_dim - stock.shape[1], 0), mode=\"constant\", value=0.0\n",
    "        )\n",
    "        for stock in indicator_tensors_list\n",
    "    ]\n",
    "    return torch.stack(padded_indicator_tensors, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1xsILvpYxNuN",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.885619Z",
     "start_time": "2023-12-06T17:46:32.850267Z"
    }
   },
   "outputs": [],
   "source": [
    "def indicators(time_series: list, _indicators: list = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate technical indicators for a given time series.\n",
    "    \"\"\"\n",
    "\n",
    "    closes = np.array([bar.close for bar in time_series], dtype=np.float64)\n",
    "    opens = np.array([bar.open for bar in time_series], dtype=np.float64)\n",
    "    highs = np.array([bar.high for bar in time_series], dtype=np.float64)\n",
    "    lows = np.array([bar.low for bar in time_series], dtype=np.float64)\n",
    "    volumes = np.array([bar.volume for bar in time_series], dtype=np.float64)\n",
    "\n",
    "    indicator_functions = {\n",
    "        \"SMA\": lambda x=closes, interval=5: talib.SMA(x, timeperiod=interval),\n",
    "        \"EMA\": lambda x=closes, interval=12: talib.EMA(x, timeperiod=interval),\n",
    "        \"WMA\": lambda x=closes, interval=12: talib.WMA(x, timeperiod=interval),\n",
    "        # \"BBANDS\" has shape (3, t), as opposed to (t)\n",
    "        # \"BBANDS\": lambda x=closes, interval=20: talib.BBANDS(\n",
    "        #     x, timeperiod=interval, nbdevup=1.5, nbdevdn=1.5\n",
    "        # ),\n",
    "        \"CCI\": lambda interval=20: talib.CCI(highs, lows, closes, timeperiod=interval),\n",
    "        \"ROC\": lambda x=closes, interval=12: talib.ROC(x, timeperiod=interval),\n",
    "        \"RSI\": lambda x=closes, interval=14: talib.RSI(x, timeperiod=interval),\n",
    "        # \"STOCH\" has shape (2, t), as opposed to (t)\n",
    "        # \"STOCH\": lambda fk=5, sk=3: talib.STOCH(\n",
    "        #     highs, lows, closes, fastk_period=fk, slowk_period=sk\n",
    "        # ),\n",
    "        \"MFI\": lambda interval=14: talib.MFI(\n",
    "            highs, lows, closes, volumes, timeperiod=interval\n",
    "        ),\n",
    "        \"SAR\": lambda a=0.02, m=0.2, interval=0: talib.SAR(\n",
    "            highs, lows, acceleration=a, maximum=m\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    indicator_tensors = []\n",
    "\n",
    "    if not _indicators:\n",
    "        for func in indicator_functions.values():\n",
    "            result = np.array(func())\n",
    "            indicator_tensor = torch.tensor(result, dtype=torch.float64)\n",
    "            indicator_tensors.append(indicator_tensor)\n",
    "    else:\n",
    "        for indicator in _indicators:\n",
    "            result = np.array(indicator_functions[indicator]())\n",
    "            indicator_tensor = torch.tensor(result, dtype=torch.float64)\n",
    "            indicator_tensors.append(indicator_tensor)\n",
    "\n",
    "    indicator_time_series = torch.stack(indicator_tensors, dim=0)\n",
    "\n",
    "    indicator_time_series = torch.nan_to_num(\n",
    "        indicator_time_series,\n",
    "        nan=0.0,\n",
    "        posinf=indicator_time_series.max(),\n",
    "        neginf=indicator_time_series.min(),\n",
    "    )\n",
    "\n",
    "    # indicator_time_series = torch.norm(\n",
    "    #     indicator_time_series + 1.0\n",
    "    # )  # Add 1 to avoid norm(0)\n",
    "\n",
    "    return indicator_time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_windows(\n",
    "    data,\n",
    "    input_window_size=60,\n",
    "    output_window_size=15,\n",
    "    log: logging.Logger = NullLogger(),\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Create input and output windows for the Vec model.\n",
    "\n",
    "    :param data: A tensor of shape (n, t, d) where n is the number of stocks, t is the number of time steps, and d is the\n",
    "    number of technical indicators.\n",
    "    :param input_window_size: The number of time steps to use as input.\n",
    "    :param output_window_size: The number of time steps to use as output.\n",
    "    :param log: A logger object.\n",
    "    :return: A tuple of tensors where the first tensor is the input data and the second tensor is the output data.\n",
    "    \"\"\"\n",
    "    input_data, output_data = [], []\n",
    "    insufficient_data_count = 0\n",
    "\n",
    "    # Loop over each stock\n",
    "    for stock_index in range(data.shape[0]):\n",
    "        stock_data = data[stock_index]  # Get data for the current stock\n",
    "        stock_input, stock_output = [], []\n",
    "\n",
    "        # Check if there are enough time steps for the current stock\n",
    "        if stock_data.shape[1] >= input_window_size + output_window_size:\n",
    "            # Create windows for the current stock\n",
    "            for i in range(\n",
    "                stock_data.shape[1] - input_window_size - output_window_size + 1\n",
    "            ):\n",
    "                input_window = stock_data[:, i : i + input_window_size]\n",
    "                output_window = stock_data[\n",
    "                    :,\n",
    "                    i + input_window_size : i + input_window_size + output_window_size,\n",
    "                ]\n",
    "                stock_input.append(input_window)\n",
    "                stock_output.append(output_window)\n",
    "\n",
    "            input_data.extend(stock_input)\n",
    "            output_data.extend(stock_output)\n",
    "        else:\n",
    "            insufficient_data_count += 1\n",
    "            print(\n",
    "                f\"Insufficient data for stock index {stock_index} with time steps: {stock_data.shape[1]}.\"\n",
    "            )\n",
    "\n",
    "        print(\n",
    "            f\"Stock index {stock_index}: Created {len(stock_input)} input windows and {len(stock_output)} output windows.\"\n",
    "        )\n",
    "\n",
    "    if input_data and output_data:\n",
    "        return torch.stack(input_data, dim=0), torch.stack(output_data, dim=0)\n",
    "    else:\n",
    "        print(\n",
    "            f\"No windows were created. Insufficient data stocks count: {insufficient_data_count}.\"\n",
    "        )\n",
    "        return torch.tensor([]), torch.tensor([])\n"
   ],
   "metadata": {
    "id": "_OLvli_Nf9-u",
    "ExecuteTime": {
     "end_time": "2023-12-06T17:46:32.887102Z",
     "start_time": "2023-12-06T17:46:32.865572Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "time_series = fetch_data(years=0.25)"
   ],
   "metadata": {
    "id": "st1KdBq6kdXu",
    "ExecuteTime": {
     "end_time": "2023-12-06T18:03:05.028022Z",
     "start_time": "2023-12-06T17:46:32.872608Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteDisconnected\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 715\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[1;32m    716\u001B[0m     conn,\n\u001B[1;32m    717\u001B[0m     method,\n\u001B[1;32m    718\u001B[0m     url,\n\u001B[1;32m    719\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[1;32m    720\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[1;32m    721\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m    722\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    723\u001B[0m )\n\u001B[1;32m    725\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    726\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    463\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    464\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    465\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    466\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 467\u001B[0m             six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:462\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 462\u001B[0m     httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:1378\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1378\u001B[0m     response\u001B[38;5;241m.\u001B[39mbegin()\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_status()\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:287\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Presumably, the server closed the connection before\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# sending a valid response.\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RemoteDisconnected(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRemote end closed connection without\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    288\u001B[0m                              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m response\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mRemoteDisconnected\u001B[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mProtocolError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/requests/adapters.py:486\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[1;32m    487\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    488\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[1;32m    489\u001B[0m         body\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mbody,\n\u001B[1;32m    490\u001B[0m         headers\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mheaders,\n\u001B[1;32m    491\u001B[0m         redirect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    492\u001B[0m         assert_same_host\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    493\u001B[0m         preload_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    494\u001B[0m         decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    495\u001B[0m         retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_retries,\n\u001B[1;32m    496\u001B[0m         timeout\u001B[38;5;241m=\u001B[39mtimeout,\n\u001B[1;32m    497\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    498\u001B[0m     )\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:799\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    797\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 799\u001B[0m retries \u001B[38;5;241m=\u001B[39m retries\u001B[38;5;241m.\u001B[39mincrement(\n\u001B[1;32m    800\u001B[0m     method, url, error\u001B[38;5;241m=\u001B[39me, _pool\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m, _stacktrace\u001B[38;5;241m=\u001B[39msys\u001B[38;5;241m.\u001B[39mexc_info()[\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m    801\u001B[0m )\n\u001B[1;32m    802\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/util/retry.py:550\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m read \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_method_retryable(method):\n\u001B[0;32m--> 550\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m six\u001B[38;5;241m.\u001B[39mreraise(\u001B[38;5;28mtype\u001B[39m(error), error, _stacktrace)\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m read \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/packages/six.py:769\u001B[0m, in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[0;32m--> 769\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:715\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 715\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_request(\n\u001B[1;32m    716\u001B[0m     conn,\n\u001B[1;32m    717\u001B[0m     method,\n\u001B[1;32m    718\u001B[0m     url,\n\u001B[1;32m    719\u001B[0m     timeout\u001B[38;5;241m=\u001B[39mtimeout_obj,\n\u001B[1;32m    720\u001B[0m     body\u001B[38;5;241m=\u001B[39mbody,\n\u001B[1;32m    721\u001B[0m     headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m    722\u001B[0m     chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    723\u001B[0m )\n\u001B[1;32m    725\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    726\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    727\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    728\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:467\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    463\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    464\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    465\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    466\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 467\u001B[0m             six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    468\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/urllib3/connectionpool.py:462\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 462\u001B[0m     httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    465\u001B[0m     \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:1378\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1377\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1378\u001B[0m     response\u001B[38;5;241m.\u001B[39mbegin()\n\u001B[1;32m   1379\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_status()\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/http/client.py:287\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Presumably, the server closed the connection before\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# sending a valid response.\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RemoteDisconnected(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRemote end closed connection without\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    288\u001B[0m                              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m response\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mProtocolError\u001B[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[15], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m time_series \u001B[38;5;241m=\u001B[39m fetch_data(years\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m)\n",
      "Cell \u001B[0;32mIn[11], line 22\u001B[0m, in \u001B[0;36mfetch_data\u001B[0;34m(years, max_workers, log)\u001B[0m\n\u001B[1;32m     11\u001B[0m     futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     12\u001B[0m         executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m     13\u001B[0m             alpaca_time_series,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m ticker \u001B[38;5;129;01min\u001B[39;00m sp_tickers\n\u001B[1;32m     19\u001B[0m     ]\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Collecting results\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m data: \u001B[38;5;28mlist\u001B[39m \u001B[38;5;241m=\u001B[39m [future\u001B[38;5;241m.\u001B[39mresult() \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m futures]\n\u001B[1;32m     23\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrieved data from the Alpaca API.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "Cell \u001B[0;32mIn[11], line 22\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     11\u001B[0m     futures \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     12\u001B[0m         executor\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m     13\u001B[0m             alpaca_time_series,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     18\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m ticker \u001B[38;5;129;01min\u001B[39;00m sp_tickers\n\u001B[1;32m     19\u001B[0m     ]\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Collecting results\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m data: \u001B[38;5;28mlist\u001B[39m \u001B[38;5;241m=\u001B[39m [future\u001B[38;5;241m.\u001B[39mresult() \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m futures]\n\u001B[1;32m     23\u001B[0m log\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRetrieved data from the Alpaca API.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/concurrent/futures/_base.py:449\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[0;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_condition\u001B[38;5;241m.\u001B[39mwait(timeout)\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/concurrent/futures/_base.py:401\u001B[0m, in \u001B[0;36mFuture.__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception:\n\u001B[1;32m    400\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 401\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\n\u001B[1;32m    402\u001B[0m     \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    403\u001B[0m         \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n\u001B[1;32m    404\u001B[0m         \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/concurrent/futures/thread.py:58\u001B[0m, in \u001B[0;36m_WorkItem.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 58\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[1;32m     59\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfuture\u001B[38;5;241m.\u001B[39mset_exception(exc)\n",
      "Cell \u001B[0;32mIn[10], line 28\u001B[0m, in \u001B[0;36malpaca_time_series\u001B[0;34m(stocks, start, end)\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# url_override=\"https://data.alpaca.markets\",\u001B[39;00m\n\u001B[1;32m     21\u001B[0m params \u001B[38;5;241m=\u001B[39m StockBarsRequest(\n\u001B[1;32m     22\u001B[0m     symbol_or_symbols\u001B[38;5;241m=\u001B[39mstocks,\n\u001B[1;32m     23\u001B[0m     start\u001B[38;5;241m=\u001B[39mstart,\n\u001B[1;32m     24\u001B[0m     end\u001B[38;5;241m=\u001B[39mend,\n\u001B[1;32m     25\u001B[0m     timeframe\u001B[38;5;241m=\u001B[39mTimeFrame\u001B[38;5;241m.\u001B[39mMinute,\n\u001B[1;32m     26\u001B[0m )\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m client\u001B[38;5;241m.\u001B[39mget_stock_bars(params)\u001B[38;5;241m.\u001B[39mdata\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/alpaca/data/historical/stock.py:92\u001B[0m, in \u001B[0;36mStockHistoricalDataClient.get_stock_bars\u001B[0;34m(self, request_params)\u001B[0m\n\u001B[1;32m     89\u001B[0m params \u001B[38;5;241m=\u001B[39m request_params\u001B[38;5;241m.\u001B[39mto_request_fields()\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m# paginated get request for market data api\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m raw_bars \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_get(\n\u001B[1;32m     93\u001B[0m     endpoint_data_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbars\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     94\u001B[0m     endpoint_asset_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstocks\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     95\u001B[0m     api_version\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m     97\u001B[0m )\n\u001B[1;32m     99\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_raw_data:\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m raw_bars\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/alpaca/data/historical/stock.py:338\u001B[0m, in \u001B[0;36mStockHistoricalDataClient._data_get\u001B[0;34m(self, endpoint_asset_class, endpoint_data_type, api_version, symbol_or_symbols, limit, page_limit, extension, **kwargs)\u001B[0m\n\u001B[1;32m    335\u001B[0m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlimit\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m actual_limit\n\u001B[1;32m    336\u001B[0m params[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpage_token\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m page_token\n\u001B[0;32m--> 338\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget(path\u001B[38;5;241m=\u001B[39mpath, data\u001B[38;5;241m=\u001B[39mparams, api_version\u001B[38;5;241m=\u001B[39mapi_version)\n\u001B[1;32m    340\u001B[0m \u001B[38;5;66;03m# TODO: Merge parsing if possible\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m extension \u001B[38;5;241m==\u001B[39m DataExtensionType\u001B[38;5;241m.\u001B[39mSNAPSHOT:\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/alpaca/common/rest.py:221\u001B[0m, in \u001B[0;36mRESTClient.get\u001B[0;34m(self, path, data, **kwargs)\u001B[0m\n\u001B[1;32m    210\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, path: \u001B[38;5;28mstr\u001B[39m, data: Union[\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m HTTPResult:\n\u001B[1;32m    211\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Performs a single GET request\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \n\u001B[1;32m    213\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;124;03m        dict: The response\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 221\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGET\u001B[39m\u001B[38;5;124m\"\u001B[39m, path, data, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/alpaca/common/rest.py:129\u001B[0m, in \u001B[0;36mRESTClient._request\u001B[0;34m(self, method, path, data, base_url, api_version)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m retry \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_one_request(method, url, opts, retry)\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m RetryException:\n\u001B[1;32m    131\u001B[0m         time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry_wait)\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/alpaca/common/rest.py:193\u001B[0m, in \u001B[0;36mRESTClient._one_request\u001B[0;34m(self, method, url, opts, retry)\u001B[0m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_one_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, method: \u001B[38;5;28mstr\u001B[39m, url: \u001B[38;5;28mstr\u001B[39m, opts: \u001B[38;5;28mdict\u001B[39m, retry: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m    175\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Perform one request, possibly raising RetryException in the case\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;124;03m    the response is 429. Otherwise, if error text contain \"code\" string,\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;124;03m    then it decodes to json object and returns APIError.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[38;5;124;03m        dict: The response data\u001B[39;00m\n\u001B[1;32m    192\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 193\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_session\u001B[38;5;241m.\u001B[39mrequest(method, url, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopts)\n\u001B[1;32m    195\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m         response\u001B[38;5;241m.\u001B[39mraise_for_status()\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(prep, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msend_kwargs)\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m adapter\u001B[38;5;241m.\u001B[39msend(request, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/anaconda3/envs/dl-quant/lib/python3.11/site-packages/requests/adapters.py:501\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    486\u001B[0m     resp \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39murlopen(\n\u001B[1;32m    487\u001B[0m         method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    488\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    497\u001B[0m         chunked\u001B[38;5;241m=\u001B[39mchunked,\n\u001B[1;32m    498\u001B[0m     )\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MaxRetryError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    504\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, ConnectTimeoutError):\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;66;03m# TODO: Remove this in 3.0.0: see #2811\u001B[39;00m\n",
      "\u001B[0;31mConnectionError\u001B[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train(\n",
    "    time_series: list,\n",
    "    normalized: bool = True,\n",
    "    epochs: int = 1_000_000,\n",
    "    log: logging.Logger = NullLogger(),\n",
    "    batch_size: int = 32,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train the Vec model.\n",
    "    \"\"\"\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        log.info(\"CUDA is available.\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        log.info(\"CUDA is not available.\")\n",
    "\n",
    "    log.info(\"Generating technical indicators for each stock...\")\n",
    "    time_series_tensor = stock_tensors(time_series)\n",
    "    log.info(\"Generated technical indicators for each stock.\")\n",
    "\n",
    "    log.info(\"Normalizing the data...\")\n",
    "    norm_data = torch.nan_to_num(\n",
    "        torch.log(time_series_tensor.detach().clone() + 1.0), nan=0.0\n",
    "    )\n",
    "    log.info(\"Normalized the data.\")\n",
    "\n",
    "    # Prepare dataset\n",
    "    print(time_series_tensor.size())\n",
    "    dataset = TimeSeriesDataset(norm_data if normalized else time_series_tensor)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Prepare data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate the model\n",
    "    transformer = Vec(dataset[0][0].shape[-1]).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
    "\n",
    "    graph_loss = []\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stopping_patience = 10\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        transformer.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = transformer(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        transformer.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(\n",
    "                    device\n",
    "                )\n",
    "                val_output = transformer(X_val_batch)\n",
    "                val_loss = criterion(val_output, y_val_batch)\n",
    "                total_val_loss += val_loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > early_stopping_patience:\n",
    "                log.info(f\"Early stopping triggered at epoch {epoch}.\")\n",
    "                break\n",
    "\n",
    "        graph_loss.append(avg_train_loss)\n",
    "\n",
    "    if not os.path.exists(\"plots\"):\n",
    "        os.mkdir(\"plots\")\n",
    "\n",
    "    plt.plot(graph_loss)\n",
    "    plt.title(\"Loss vs. Epochs (Normalized)\" if normalized else \"Loss vs. Epochs\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"plots/loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    log.info(\"Saving transformer.pt...\")\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "\n",
    "    torch.save(transformer.state_dict(), \"models/transformer.pt\")\n",
    "    log.info(\"Saved transformer.pt\")\n"
   ],
   "metadata": {
    "id": "mae8RsXzaf_3",
    "ExecuteTime": {
     "start_time": "2023-12-06T18:03:05.024149Z"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train(time_series=time_series)"
   ],
   "metadata": {
    "id": "YMSK7OoRatP6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "outputId": "d831ee7b-9a70-4612-a404-0dfb2ff2a1bf",
    "ExecuteTime": {
     "end_time": "2023-12-06T18:03:05.032275Z",
     "start_time": "2023-12-06T18:03:05.030865Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "gpuType": "V100"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
